# ğŸ” Lighthouse - ì›¹ ì½˜í…ì¸  í¬ë¡¤ë§ ë° ë¶„ì„ ì‹œìŠ¤í…œ

> í•œêµ­ ì˜¨ë¼ì¸ ì½˜í…ì¸  ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì •ì¹˜ ì„±í–¥ ë¶„ì„ í”Œë«í¼

## ğŸ“‹ ê°œìš”

LighthouseëŠ” í•œêµ­ì˜ ë‹¤ì–‘í•œ ì˜¨ë¼ì¸ í”Œë«í¼(ë‰´ìŠ¤, ì»¤ë®¤ë‹ˆí‹°, SNS)ì—ì„œ ì½˜í…ì¸ ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , NLP ê¸°ë°˜ìœ¼ë¡œ ì •ì¹˜ ì„±í–¥ê³¼ ì—¬ë¡  ë™í–¥ì„ ë¶„ì„í•˜ëŠ” ì¢…í•© ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ğŸ¯ í•µì‹¬ ê°€ì¹˜

- **ì‹¤ì‹œê°„ ì—¬ë¡  ëª¨ë‹ˆí„°ë§**: 24/7 ìë™ í¬ë¡¤ë§ìœ¼ë¡œ ìµœì‹  íŠ¸ë Œë“œ í¬ì°©
- **ì •ì¹˜ ì„±í–¥ ë¶„ì„**: NLP ê¸°ë°˜ ì§„ë³´/ì¤‘ë„/ë³´ìˆ˜ ìë™ ë¶„ë¥˜
- **ë‹¤ì°¨ì› ë¶„ì„**: ê°ì • ë¶„ì„, í‚¤ì›Œë“œ ì¶”ì¶œ, íŠ¸ë Œë“œ ê°ì§€
- **ìˆ˜ë™ ëª¨ë‹ˆí„°ë§ ëŒ€ë¹„ 90% ì‹œê°„ ì ˆê°**

## âœ¨ ì£¼ìš” ê¸°ëŠ¥

### 1. ì§€ëŠ¥í˜• ì›¹ í¬ë¡¤ë§ ì—”ì§„
- ğŸ”¸ ì ì‘í˜• íŒŒì„œë¡œ ì‚¬ì´íŠ¸ êµ¬ì¡° ìë™ í•™ìŠµ
- ğŸ”¸ ë™ì  ì½˜í…ì¸ (JavaScript) ë Œë”ë§ ì§€ì›
- ğŸ”¸ Rate limiting ë° í”„ë¡ì‹œ ë¡œí…Œì´ì…˜
- ğŸ”¸ User-Agent ë¡œí…Œì´ì…˜ ë° robots.txt ì¤€ìˆ˜

### 2. NLP ê¸°ë°˜ ì½˜í…ì¸  ë¶„ì„
- ğŸ”¸ ì •ì¹˜ ì„±í–¥ ë¶„ë¥˜ (ì§„ë³´/ì¤‘ë„/ë³´ìˆ˜)
- ğŸ”¸ ê°ì • ë¶„ì„ (ê¸ì •/ë¶€ì •/ì¤‘ë¦½)
- ğŸ”¸ í•µì‹¬ í‚¤ì›Œë“œ ë° ê°œì²´ëª… ì¶”ì¶œ
- ğŸ”¸ ì‹œê³„ì—´ íŠ¸ë Œë“œ ë¶„ì„

### 3. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
- ğŸ”¸ WebSocket ê¸°ë°˜ ë¼ì´ë¸Œ ì—…ë°ì´íŠ¸
- ğŸ”¸ ì»¤ìŠ¤í„°ë§ˆì´ì§• ê°€ëŠ¥í•œ ìœ„ì ¯
- ğŸ”¸ ì•Œë¦¼ ë° ì´ìƒ ì§•í›„ ê°ì§€
- ğŸ”¸ ë‹¤ì–‘í•œ ì°¨íŠ¸ ë° ì‹œê°í™”

### 4. ê³ ê¸‰ ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ
- ğŸ”¸ í¼ì§€ ë§¤ì¹­ìœ¼ë¡œ ìœ ì‚¬ ì½˜í…ì¸  ê°ì§€
- ğŸ”¸ í¬ë¡œìŠ¤ í”Œë«í¼ ì¤‘ë³µ ì œê±°
- ğŸ”¸ ì›ë³¸ ì¶œì²˜ ìë™ ì¶”ì 

## ğŸ› ï¸ ê¸°ìˆ  ìŠ¤íƒ

### Backend
- **Framework**: Node.js, TypeScript
- **Monorepo**: Nx workspace with pnpm
- **ORM**: Prisma with MySQL 8.0
- **Queue**: Redis with BullMQ
- **Search**: Elasticsearch 8.x

### Crawling & Analysis
- **Browser Automation**: Playwright
- **HTTP Client**: Axios
- **NLP**: Korean language processing (ì˜ˆì •: KoBERT)
- **Rate Limiting**: Bottleneck

### Infrastructure
- **Container**: Docker Compose
- **Task Management**: Task Master AI
- **Development**: Claude Code + Cursor IDE integration

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
lighthouse/
â”œâ”€â”€ apps/                    # ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”œâ”€â”€ api/                # REST API ì„œë²„
â”‚   â””â”€â”€ dashboard/          # ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ
â”œâ”€â”€ libs/                   # ê³µìœ  ë¼ì´ë¸ŒëŸ¬ë¦¬
â”‚   â”œâ”€â”€ crawler-core/       # í¬ë¡¤ëŸ¬ í”„ë ˆì„ì›Œí¬
â”‚   â”œâ”€â”€ database/          # Prisma & DB ë¡œì§
â”‚   â””â”€â”€ analyzer/          # NLP ë¶„ì„ ì—”ì§„
â”œâ”€â”€ docker/                # Docker ì„¤ì •
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ init.sql
â”œâ”€â”€ prisma/               # ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ
â”‚   â”œâ”€â”€ schema.prisma
â”‚   â””â”€â”€ migrations/
â”œâ”€â”€ .taskmaster/          # Task Master ì„¤ì •
â”‚   â”œâ”€â”€ config.json
â”‚   â”œâ”€â”€ docs/
â”‚   â””â”€â”€ tasks/
â””â”€â”€ .claude/             # Claude Code ì„¤ì •
```

## ğŸš€ Quick Start

### Prerequisites

- Node.js 20.x ì´ìƒ
- Docker & Docker Compose
- pnpm (`npm install -g pnpm`)

### 1. í™˜ê²½ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ í´ë¡ 
git clone https://github.com/your-org/lighthouse.git
cd lighthouse

# ì˜ì¡´ì„± ì„¤ì¹˜
pnpm install

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
cp .env.example .env.local
```

### 2. Docker ì¸í”„ë¼ ì‹¤í–‰

```bash
# MySQL, Redis, Elasticsearch ì‹œì‘
docker-compose -f docker/docker-compose.yml up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose -f docker/docker-compose.yml ps
```

### 3. ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”

```bash
# Prisma ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
npx prisma migrate dev

# ì‹œë“œ ë°ì´í„° ìƒì„±
npx prisma db seed
```

### 4. ê°œë°œ ì„œë²„ ì‹¤í–‰

```bash
# Nx ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ë¹Œë“œ
pnpm nx run-many --target=build --all

# ê°œë°œ ì„œë²„ ì‹œì‘
pnpm nx serve api
```

### 5. ì²« í¬ë¡¤ëŸ¬ ì‹¤í–‰

```bash
# í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ ì‹¤í–‰
pnpm nx run crawler-core:crawl --source=test-news
```

## ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### í•µì‹¬ ì—”í‹°í‹°

- **Source**: í¬ë¡¤ë§ ëŒ€ìƒ ì‚¬ì´íŠ¸ ì •ë³´
- **Content**: ìˆ˜ì§‘ëœ ì½˜í…ì¸  (ê¸°ì‚¬, í¬ìŠ¤íŠ¸ ë“±)
- **Analysis**: ë¶„ì„ ê²°ê³¼ (ì •ì¹˜ì„±í–¥, ê°ì • ë“±)
- **User**: ì‹œìŠ¤í…œ ì‚¬ìš©ì
- **Job**: í¬ë¡¤ë§/ë¶„ì„ ì‘ì—… í

## ğŸ—ºï¸ ê°œë°œ ë¡œë“œë§µ

### Phase 1: MVP âœ… (ì§„í–‰ì¤‘)
- [x] í”„ë¡œì íŠ¸ ì¸í”„ë¼ ì„¤ì •
- [ ] ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ êµ¬í˜„
- [ ] BaseCrawler í”„ë ˆì„ì›Œí¬
- [ ] ë‹¨ì¼ ë‰´ìŠ¤ ì‚¬ì´íŠ¸ í¬ë¡¤ëŸ¬
- [ ] ê¸°ë³¸ Admin UI

### Phase 2: ë©€í‹° ì†ŒìŠ¤ ì§€ì›
- [ ] 3ê°œ ì£¼ìš” ì‹ ë¬¸ì‚¬ í¬ë¡¤ëŸ¬
- [ ] DCì¸ì‚¬ì´ë“œ/í´ë¦¬ì•™ í¬ë¡¤ëŸ¬
- [ ] ì¤‘ë³µ ì œê±° ì‹œìŠ¤í…œ
- [ ] í¬ë¡¤ëŸ¬ ëª¨ë‹ˆí„°ë§

### Phase 3: NLP ë¶„ì„ ê¸°ëŠ¥
- [ ] KoBERT ì •ì¹˜ ì„±í–¥ ë¶„ì„
- [ ] ê°ì • ë¶„ì„ ëª¨ë¸
- [ ] Elasticsearch í†µí•©
- [ ] ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ

### Phase 4: í™•ì¥ ë° ìµœì í™”
- [ ] ë¶„ì‚° í¬ë¡¤ë§ ì‹œìŠ¤í…œ
- [ ] API í”Œë«í¼ êµ¬ì¶•
- [ ] ê³ ê¸‰ ì‹œê°í™”
- [ ] ì„±ëŠ¥ ìµœì í™”

### Phase 5: ì—”í„°í”„ë¼ì´ì¦ˆ
- [ ] ë‹¤ì¤‘ í…Œë„ŒíŠ¸ ì§€ì›
- [ ] SSO ë° 2FA
- [ ] AI ê¸°ë°˜ ìë™ ìš”ì•½
- [ ] í”ŒëŸ¬ê·¸ì¸ ì‹œìŠ¤í…œ

## ğŸ”§ Task Master í†µí•©

LighthouseëŠ” Task Master AIë¥¼ í†µí•´ PRD ê¸°ë°˜ ì‘ì—… ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

### í˜„ì¬ ì‘ì—… ìƒíƒœ

```bash
# ë‹¤ìŒ ì‘ì—… í™•ì¸
npx task-master next

# ì‘ì—… ìƒì„¸ ë³´ê¸°
npx task-master show <id>

# ì‘ì—… ì™„ë£Œ í‘œì‹œ
npx task-master set-status --id=<id> --status=done
```

### ì‘ì—… í†µê³„
- **ì´ ì‘ì—…**: 11ê°œ ë©”ì¸ íƒœìŠ¤í¬
- **ì„œë¸ŒíƒœìŠ¤í¬**: 35ê°œ ì´ìƒ
- **í˜„ì¬ ì§„í–‰**: ì¸í”„ë¼ ì„¤ì • ë° ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

## ğŸ”Œ API ë¬¸ì„œ

### ì¸ì¦
```http
POST /api/auth/login
Content-Type: application/json

{
  "email": "user@example.com",
  "password": "password"
}
```

### í¬ë¡¤ë§ ì‘ì—…
```http
POST /api/jobs/crawl
Authorization: Bearer <token>

{
  "sourceId": "uuid",
  "priority": "high"
}
```

### ì½˜í…ì¸  ê²€ìƒ‰
```http
GET /api/contents/search?q=keyword&from=2024-01-01
Authorization: Bearer <token>
```

## ğŸ‘¨â€ğŸ’» ê°œë°œ ê°€ì´ë“œ

### ìƒˆ í¬ë¡¤ëŸ¬ ì¶”ê°€

1. `libs/crawler-core/src/crawlers/` ë””ë ‰í† ë¦¬ì— ìƒˆ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ìƒì„±
2. `BaseCrawler` í´ë˜ìŠ¤ ìƒì†
3. `parseContent()` ë° `validateResponse()` ë©”ì„œë“œ êµ¬í˜„
4. í¬ë¡¤ëŸ¬ íŒ©í† ë¦¬ì— ë“±ë¡

```typescript
// libs/crawler-core/src/crawlers/NewsCrawler.ts
export class NewsCrawler extends BaseCrawler {
  async parseContent(html: string): Promise<ParsedContent> {
    // íŒŒì‹± ë¡œì§ êµ¬í˜„
  }
}
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
# ìœ ë‹› í…ŒìŠ¤íŠ¸
pnpm nx test crawler-core

# E2E í…ŒìŠ¤íŠ¸
pnpm nx e2e api-e2e

# ëª¨ë“  í…ŒìŠ¤íŠ¸
pnpm nx run-many --target=test --all
```

## ğŸ“š ë¬¸ì„œ

- [API ë¬¸ì„œ](./docs/api.md)
- [í¬ë¡¤ëŸ¬ ê°€ì´ë“œ](./docs/crawler.md)
- [ë¶„ì„ê¸° ê°€ì´ë“œ](./docs/analyzer.md)
- [ë°°í¬ ê°€ì´ë“œ](./docs/deployment.md)

## âš–ï¸ ë²•ì  ê³ ë ¤ì‚¬í•­

- **robots.txt ì¤€ìˆ˜**: ëª¨ë“  í¬ë¡¤ëŸ¬ëŠ” robots.txt ì •ì±…ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤
- **ì €ì‘ê¶Œ**: ìˆ˜ì§‘ëœ ì½˜í…ì¸ ì˜ ì €ì‘ê¶Œì€ ì› ì €ì‘ìì—ê²Œ ìˆìŠµë‹ˆë‹¤
- **ê°œì¸ì •ë³´ë³´í˜¸**: KISA ê°œì¸ì •ë³´ë³´í˜¸ ê°€ì´ë“œë¼ì¸ ì¤€ìˆ˜
- **Rate Limiting**: ëŒ€ìƒ ì„œë²„ì— ë¶€í•˜ë¥¼ ì£¼ì§€ ì•Šë„ë¡ ìš”ì²­ ì†ë„ ì œí•œ

## ğŸ¤ ê¸°ì—¬í•˜ê¸°

ê¸°ì—¬ë¥¼ í™˜ì˜í•©ë‹ˆë‹¤! PRì„ ì œì¶œí•˜ê¸° ì „ì— ë‹¤ìŒ ì‚¬í•­ì„ í™•ì¸í•´ì£¼ì„¸ìš”:

1. ì½”ë“œ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¤€ìˆ˜
2. í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
3. ë¬¸ì„œ ì—…ë°ì´íŠ¸
4. PR í…œí”Œë¦¿ ì‘ì„±

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

---

**Built with â¤ï¸ for Real-time Korean Content Analysis**